# 希姆计算性能分析工具使用说明

## 版本历史

| **版本** | **对应产品版本**   | **作者** | **日期**   | **描述**                         |
| -------- | ------------------ | -------- | ---------- | -------------------------------- |
| V1.10.3  | STCRP V1.5.1       | 希姆计算 | 2024-01-15 | 基于STCRP V1.5.1验证文档内容。   |
| V1.10.2  | STCRP V1.5.0       | 希姆计算 | 2023-07-24 | 基于STCRP V1.5.0验证文档内容。   |
| V1.10.1  | gem5 V1.3.3        | 希姆计算 | 2023-01-16 | 基于gem5 V1.3.3验证文档内容。    |
| V1.10.0  | gem5 V1.3.0        | 希姆计算 | 2023-01-03 | 配合gem5 V1.3.0发布文档。        |
| V1.9.0   | STCRP V1.2.0       | 希姆计算 | 2022-11-24 | 配合STCRP V1.2.0发布文档。       |
| V1.8.0   | TensorTurbo V1.8.0 | 希姆计算 | 2022-08-29 | 增加示例。                       |
| V1.7.0   | TensorTurbo V1.7.0 | 希姆计算 | 2022-07-07 | 配合TensorTurbo V1.7.0发布文档。 |

## 概述

性能分析工具可帮助您在整网性能调试时，定位出网络模型可能存在的性能问题。它是通过gem5模拟得到模型在NPU上推理时，各条指令的执行和并行度情况，进而与深度学习编译器编译得到的指令表达对照，分析出可能存在性能瓶颈的节点位置。基于gem5社区版本完成了如下功能开发：

- 支持RISC-V64/32 Baremetal

- 实现了RISC-V Vector指令扩展, 目前已更新到V0.8

- 实现了Andes AndeStar V5指令扩展，版本为v1.4

- 实现了STCP920的NPU建模

- 实现了希姆的NPU定制指令扩展

- 实现了RISC-V Vector和NPU定制指令的单元测试用例

- 添加了性能相关的debug信息及适配stc-vprof可视化工具用于性能分析

gem5目前有以下的限制及已知问题：

1. gem5仅限支持bank0仿真，不支持多bank/cluster及跨bank的资源访问的仿真。

2. 目前硬件实现时LLB的地址，0xFA00_0000用于DMA传输，0xFA00_0000用于pld/mov.llb*指令，它们实际是同一物理内存，仿真逻辑与硬件实现一致。此问题，还会导致mov.llb*指令进入内存总线的竞争情况不一致，出现较大的误差。

3. gem5 cpu（mcu）的仿真周期小程序误差可能较大（主要是分支预测的实现问题），全网络误差较小。

## 操作步骤

### 环境准备

- 目前gem5支持在Debian9、Debian10、Ubuntu1804、Ubuntu2004等主流Linux操作系统中运行。

   > 说明：请联系希姆计算技术支持获得gem5安装包。
   >

- 已安装Python，如有运行模型需求，建议安装Python3.6以上版本。

- 如果需要执行TensorTurbo测试用例，请确保安装TensorTurbo，且版本不低于V1.12.0。

- 已安装必需的依赖软件：
   ```bash
   $ sudo apt-get install -y python3-virtualenv python2-dev python-six
   ```

- 配置环境变量，示例如下：

   

   ```bash
   $ export PATH=~/opt/riscv/bin:$PATH
   $ export gem5_options="--debug-flags=StcPerf"
   ```

   

   > 注意：gem5_options这个环境变量非常重要，尤其是服务器重启后重新进入虚拟机，很容易忘记设置。可以考虑添加到 ~/.bashrc 中。

### 安装步骤

1. 安装gem5，推荐切换至root用户安装，执行下面的命令，将自动安装好gem5：
   
   
   
   获取安装包后安装。
   
   ```bash
   $ bash gem5-1.3.3-stc
   ```
   
   
   
   > 说明：如果没有root用户的权限，也可以考虑使用拥有sudo权限的普通用户安装，使用sudo命令进行安装。

### 使用步骤

1. 编译期望分析性能的用例，得到对应的.out文件。
   - 设置环境变量
     ```bash
     $ export TVM_STC_DUMP_GOLDEN=ON
     $ export TVM_CONST_DEBUG=ON
     ```
     
     > 说明：`TVM_STC_DUMP_GOLDEN`环境变量用于控制生成.out文件，建议可在默认环境变量中直接设置。`TVM_CONST_DEBUG`环境变量用于保存二进制常量文件，若生成.out文件过程中不需要保存常量文件，则可不设置该环境变量。
     
   - 运行模型用例
     
     ```bash
     $ python -m pytest -s test_deepfm.py::test_deepfm
     ```
     
     在当前目录下会自动生成.out文件。
   
2. 使用gem5运行.out文件。
   使用gem5运行编译出来的.out可执行文件，以名为a.out为例，将生成出来的性能数据写入perf.log。

   > 说明：为减少gem5执行时间，可设置环境变量`STC_PERF_ONLY`为yes，在执行时只计算理论cycle数而不做实际计算。

   ```bash
   $ export gem5_options="--debug-flags=StcPerf"
   $ gem5 -p 8 -b a.out > perf.log
   ```

3. 使用parser脚本将perf.log中的性能数据转换成tracing格式文件。
   在当前目录下，会生成名为perf_events.json的文件。

   ```bash
   $ gem5-perf-parser -f perf.log
   ```

   通过使用-o参数，在生成的perf_events.json的文件中将会包含pc对应的源代码信息。示例如下，其中a.out为第二步中重新编译生成的可执行文件：

   ```bash
   $ gem5-perf-parser -f perf.log -o a.out
   ```

   > 说明：通过指定-o参数得到的json文件更大，运行时间也更长，请只在分析算子或小网络时使用。

4. 生成的perf_events.json文件可放在可视化工具里查看，目前支持两种查看方式：

   - 使用Chrome浏览器打开chrome://tracing, 在菜单栏点击**Load**，选择perf_events.json文件进行加载后，即可看到调度信息（打点图）。

      - 其中信息部分如下图：

      ![](/_static/images/gem5-01.png)

     > 快捷键：
     >
     > - A：左移
     >
     > - D：右移
     >
     > - W：放大鼠标所在打点图
     >
     > - S：缩小鼠标所在打点图

   - 使用stc-vprof可视化性能分析工具，查看分析结果。详细使用方法可参考[希姆计算stc-vprof使用说明](https://docs.streamcomputing.com/zh/latest/hpe/希姆计算stc-vprof使用说明.html)。

## 调优示例

### 示例一

本示例将会以video-bert网络模型为示例，进行性能优化分析。

按照操作步骤获取性能数据，分析性能问题。在进行性能分析时，主要分析三个文件：编译生成的.cc文件、编译生成的图调度文件以及性能打点图。

- 通过设置环境变量TVM_STC_DUMP_GOLDEN为ON，会在模型用例运行的当前目录生成.cc文件。

- 添加`"tb.graph_dump_file": "xxx.sch"`配置，生成图调度文件。

- 使用性能分析工具，可生成性能打点图。

#### 打点图出现大片空白

分析性能打点图，发现打点图上的一些调度不合理的地方。

下图所示，计算部分主要是后面的红框部分，而前面有一大片的DMA，这部分的占用时间几乎是计算的三倍时间，占比非常大。

![](/_static/images/gem5-02.png)

> 说明：针对打点图上的一些调度不合理的地方，可以具体分析一下是由什么指令造成的。

查看模型的.cc文件和图调度文件，分析这部分DMA是由什么引起的，是否有优化空间。从.cc文件中看出，这部分主要是搬运指令，数据从DDR搬运到LLB，并占用一个for循环，导致这部分时间占用非常大。

![](/_static/images/gem5-03.png)

经过一系列的优化后，性能打点图中大片的DMA已经去除，只剩下整个计算部分，此次优化性能提升较大，目前性能打点图上已经看上去比较紧密。

![](/_static/images/gem5-04.png)

#### mem_scope指令占比过大

接着继续分析性能打点图和图调度文件。在图调度文件中搜索mem_scope为LLB和DDR的指令，发现这部分指令占比较大，可见在图调度时memory分配不合理，这个问题有可能的原因是group切分或者是spilt group造成的，或者是memory本身分配不合理。

![](/_static/images/gem5-05.png)

该模型是resnet50的一个变种，其分组和切分看上去问题不大。排除group切分或者是spilt group的问题，目前考虑手写图调度，合理安排内存。

> 说明：在调整memory scope和core bind时，遵循的原则是尽量按照L1->LLB->DDR的优先级进行安排，core bind尽量的用满所有的core，不要让core空跑。

#### 多个连续的move_l1_llb

再回到性能打点图上，目前指令看上去很紧密，但仔细分析发现打点图上还是有一些空隙存在，如图中红圈部分，这部分有还存在优化的可能性。

![](/_static/images/gem5-06.png)

放大后发现这里是很多连续的mov_l1_llb, 也就是有比较多的数据放到了LLB，随即定位到这是concatenate的地方，经过推断发现之前写的图调度里有concatenate还可以放到L1，不用溢出到LLB。

![](/_static/images/gem5-07.png)

调整图调度文件之后，性能有大幅度的提升。

通过这个示例的分析可以看出，整个分析过程就是不断的找瓶颈然后解决。解决性能比较奏效的方式还是手动图调度。经过不断的调整图调度和corebind，性能会有非常显著的提升，带来的收益也比较大。

### 示例二

本示例将会以某搜推类网络模型为示例，进行性能优化分析。按照操作步骤获取性能数据，分析性能问题。

#### 未做拷贝消除

分析性能打点图，发现大量的DMA搬运，这部分时间占比太大，需要考虑优化。

![](/_static/images/gem5-08.png)

查看模型的.cc文件和图调度文件，存在大量dmaq_add_llb_ddr。目前是在DDR上分批搬运到LLB后，在LLB中拼接成一整块连续的数据，最后再搬回到DDR上。而涉及到的concat算子是在DDR，并且四个输入也在DDR，理论上是不需要从DDR搬运到LLB后，再搬回到DDR上，四个输入可以直接写到concat的DDR上。所以性能打点图上存在大量的dmaq_add_llb_ddr。

![](/_static/images/gem5-09.png)

通过对concat算子优化后，减少了DMA的数量，提升了性能。在性能打点图上可以看出，减少了DMA搬运时间的占比。

![](/_static/images/gem5-10.png)
